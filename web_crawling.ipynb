{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web crawling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the html contains a simple table you can load it directly into a dataframe\n",
    "\n",
    "# very useful with wikipedia\n",
    "\n",
    "# example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from exercise for Maria Chiara dati elezioni\n",
    "\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "\n",
    "# how to extract all links from a webpage: https://www.pythonforbeginners.com/beautifulsoup/beautifulsoup-4-python\n",
    "# see https://www.crummy.com/software/BeautifulSoup/bs4/doc/#quick-start\n",
    "\n",
    "Liste = ['CASAPOUND ITALIA',\n",
    "         ...\n",
    "         'ITALIA EUROPA INSIEME',\n",
    "         'PARTITO DEMOCRATICO']\n",
    "         \n",
    "c1_page = 'https://wwwext.comune.fi.it/elettorale/poli2018/sezioneList_CE_01_ELE_2_SC_2_TYPE_collegioCamerale.htm'\n",
    "c2_page = 'https://wwwext.comune.fi.it/elettorale/poli2018/sezioneList_CE_02_ELE_2_SC_2_TYPE_collegioCamerale.htm'\n",
    "\n",
    "mypage = 'https://wwwext.comune.fi.it/elettorale/poli2018/elezioneRisultati_CESEZ_02_ELE_2_SC_2_SEZ_7.htm'\n",
    "\n",
    "str_header = 'Collegio,Sezione'\n",
    "for Lista in Liste:\n",
    "    str_header = str_header + ',' + Lista\n",
    "print(str_header)\n",
    "\n",
    "collegio_nr = 2\n",
    "webpage = c2_page\n",
    "#print(\"Risultati for page: %s\" % webpage)\n",
    "\n",
    "collegio = []\n",
    "\n",
    "html = urllib.request.urlopen(webpage)\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "for link in soup.find_all('a'):\n",
    "    url = link.get('href')\n",
    "    match = re.search('CESEZ', url)\n",
    "    if match:\n",
    "        completeURL = 'https://wwwext.comune.fi.it/elettorale/poli2018/' + url\n",
    "        collegio.append(completeURL)\n",
    "        #print(completeURL)\n",
    "\n",
    "n_sezioni = 0\n",
    "\n",
    "for sezioneURL in collegio:\n",
    "    #print(sezioneURL)\n",
    "   \n",
    "    # extract sezione n.\n",
    "    #sezioneURL = 'https://wwwext.comune.fi.it/elettorale/poli2018/elezioneRisultati_CESEZ_02_ELE_2_SC_2_SEZ_7.htm'\n",
    "    # extract sezione n. :\n",
    "    entries = re.split(\"_SEZ_\", sezioneURL)\n",
    "    #print(entries[1])\n",
    "    entries2 = re.split(\"\\.\", entries[1])\n",
    "    #print(entries2[0])\n",
    "    Sezione_n = int(entries2[0])\n",
    "\n",
    "    #print('Sezione n. %d' % Sezione_n)\n",
    "    n_sezioni += 1\n",
    "    \n",
    "    Html_file= urllib.request.urlopen(sezioneURL)\n",
    "    soup = BeautifulSoup(Html_file, \"html.parser\")\n",
    "\n",
    "  \n",
    "    #table = soup.findAll(\"table\", {\"class\":\"table-responsive\"})[0]\n",
    "\n",
    "    first_table = soup.find(\"table\", {\"class\":\"table-responsive\"})\n",
    "    #print(first_table)\n",
    "    # this is one single table with the results, from which to extract the two columns Lista-Voti\n",
    "\n",
    "    #print('Sezione n. %d' % Sezione_n)\n",
    "\n",
    "    row_str = str(collegio_nr) + ',' + str(Sezione_n)\n",
    "\n",
    "    for search_Lista in Liste:\n",
    "        #print(search_Lista)\n",
    "          \n",
    "        stripped_string = ''\n",
    "\n",
    "        for td_tag in first_table.find_all(\"td\"):\n",
    "            stripped_string=str(td_tag.contents[0])\n",
    "            stripped_string=stripped_string.strip()\n",
    "            #if stripped_string != '':\n",
    "             #   print('\\nstripped_str:%s-' % stripped_string)\n",
    "            \n",
    "            match = re.search(search_Lista, stripped_string)\n",
    "        \n",
    "            if match:     \n",
    "                next_line = td_tag.find_next_sibling(\"td\")\n",
    "                voti = str(next_line.contents[0])\n",
    "                voti = voti.replace('<span>','')\n",
    "                voti = voti.replace('</span>','')\n",
    "                voti = voti.strip()\n",
    "                #risultato = stripped_string + ',' + voti\n",
    "                #print(risultato)\n",
    "                row_str = row_str + ',' + voti\n",
    "                break\n",
    "    print(row_str)\n",
    "    #break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
